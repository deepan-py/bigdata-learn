{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aac930c-bda2-47e8-b0ec-783d86e5713f",
   "metadata": {},
   "source": [
    "## Read Data in Chunks\n",
    "\n",
    "Earlier we have seen how to load the data into target database in chunks. Let us also explore how to read the data from large files in chunks for processing.\n",
    "\n",
    "Here are the steps we need to follow:\n",
    "* Make sure to read the data into manageable chunks from the file.\n",
    "* If we invoke `pd.read_csv` with `chunksize` then it will return **TextReader**. We can iterate through the TextReader which will return one Dataframe per chunk.\n",
    "* We can process each chunk in the Dataframe based upon the requirements.\n",
    "* In our case for each chunk, we will drop fields that are not required, rename the fields as per the target and then load the data to the target MongoDB database collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2cb36-e62a-4551-a829-77922f30f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cccc892-ca8c-4d95-854a-835e72803551",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b9377-0cc3-45f2-b6c2-d9813789dc48",
   "metadata": {},
   "source": [
    "* Read the data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebf636-fff6-4000-8151-6976bff57ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv(\n",
    "    '/data/ecomm/customers/part-00000', \n",
    "    iterator=True, \n",
    "    chunksize=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d3b4f-6485-4c68-8757-8589a6e8185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92574f-8995-47f9-b576-ab26488c2938",
   "metadata": {},
   "source": [
    "* Get list of fields that need to be dropped as well as mapping between source and target columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd967b-408a-431d-9730-1fc41ee0868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping_str = '''{\n",
    "    \"customer_first_name\": {\"target_field_name\": \"FirstName\", \"is_required\": true},\n",
    "    \"customer_last_name\": {\"target_field_name\": \"LastName\", \"is_required\": true},\n",
    "    \"customer_email\": {\"target_field_name\": \"Email\", \"is_required\": true},\n",
    "    \"product_name\": {\"is_required\": false},\n",
    "    \"product_subscription\": {\"is_required\": false}\n",
    "}'''\n",
    "\n",
    "import json\n",
    "column_mapping = json.loads(column_mapping_str)\n",
    "\n",
    "# Assigning the list of not required fields to a variable\n",
    "columns_to_be_dropped = dict(\n",
    "    list(\n",
    "        filter(\n",
    "            lambda col: not col[1]['is_required'], \n",
    "            column_mapping.items()\n",
    "        )\n",
    "    )\n",
    ").keys()\n",
    "\n",
    "required_columns_list = list(\n",
    "    filter(\n",
    "        lambda col: col[1]['is_required'], \n",
    "        column_mapping.items()\n",
    "    )\n",
    ")\n",
    "\n",
    "required_columns_mapping = dict(\n",
    "    map(\n",
    "        lambda col: (col[0], col[1]['target_field_name']), \n",
    "        required_columns_list\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31758602-e579-4952-bae9-3e10e20cf019",
   "metadata": {},
   "source": [
    "* Create MongoDB Connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a315d5a-2878-409a-b6b3-8950d7e9b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo, getpass, configparser\n",
    "\n",
    "username = getpass.getuser()\n",
    "config = configparser.ConfigParser()\n",
    "config.read(f'/home/{username}/.jupyterenv')\n",
    "\n",
    "client = pymongo.MongoClient(\n",
    "    host='pylabsmd.itversity.com', \n",
    "    username=f'{username}_scratch_user', \n",
    "    password=config['DEFAULT']['MONGO_SCRATCH_PASS'], \n",
    "    authSource='admin'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac7c2f-bf9c-4ffb-8bae-5b5986adc1c4",
   "metadata": {},
   "source": [
    "* Cleanup the data in the collection before loading so that we will not end up with duplicate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffc6ac-c13e-4cf6-a91a-7ebc3b7a793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client[f'{username}_scratch_db']['customers'].delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df112c65-7ea0-4e74-b2ff-cb3471f75107",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in client[f'{username}_scratch_db']['customers'].find({}):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84dfb8-0e7e-4d00-8053-05e77075d61d",
   "metadata": {},
   "source": [
    "* Process and store data into MongoDB collection in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae07274-ebab-4409-b423-33a815a8f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, chunk in enumerate(customers):\n",
    "    print(f'Processing chunk {idx}')\n",
    "\n",
    "    # This will take care of dropping the not required fields \n",
    "    # and rename others as per mapping\n",
    "    customers_target = chunk. \\\n",
    "        drop(columns=columns_to_be_dropped). \\\n",
    "        rename(columns=required_columns_mapping)\n",
    "    \n",
    "    customers_list = customers_target.to_dict(orient='records')\n",
    "    client[f'{username}_scratch_db']['customers'].insert_many(customers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4ff14-e397-4f4c-91f2-aab7a9dfc456",
   "metadata": {},
   "source": [
    "* Validate whether all the data is copied succesfully or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb855fa-cd74-4d3a-ae41-b1414a692f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in client[f'{username}_scratch_db']['customers'].find({}):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadef7dd-b2b7-4304-ac97-2ee9c8c0616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client[f'{username}_scratch_db']['customers'].count_documents({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
